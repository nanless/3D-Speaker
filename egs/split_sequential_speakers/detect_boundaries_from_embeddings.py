#!/usr/bin/env python3
# Copyright 3D-Speaker (https://github.com/alibaba-damo-academy/3D-Speaker). All Rights Reserved.
# Licensed under the Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0)

"""
åŸºäºé¢„æå–embeddingçš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹è„šæœ¬
ä»embeddingæ–‡ä»¶ä¸­è¯»å–æ•°æ®è¿›è¡Œè¾¹ç•Œæ£€æµ‹å’Œè¯´è¯äººåˆ†å‰²
"""

import os
import sys
import json
import numpy as np
import argparse
import pickle
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.mixture import GaussianMixture
import seaborn as sns
from collections import defaultdict
import warnings
import time
import shutil
warnings.filterwarnings('ignore')

def load_embeddings_from_merged_file(embeddings_file):
    """ä»åˆå¹¶çš„embeddingæ–‡ä»¶åŠ è½½æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½åˆå¹¶çš„embeddingæ–‡ä»¶: {embeddings_file}")
    
    try:
        with open(embeddings_file, 'rb') as f:
            all_embeddings_data = pickle.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(all_embeddings_data)} ä¸ªembedding")
        
        # æŒ‰éŸ³é¢‘æ–‡ä»¶è·¯å¾„æ’åºç¡®ä¿é¡ºåº
        all_embeddings_data.sort(key=lambda x: x['audio_file'])
        
        # æå–embeddingçŸ©é˜µå’ŒéŸ³é¢‘ä¿¡æ¯
        embeddings = []
        audio_info = []
        failed_count = 0
        
        for data in all_embeddings_data:
            try:
                embedding = data['embedding']
                if embedding is not None and len(embedding) > 0:
                    embeddings.append(embedding)
                    
                    # ç¡®ä¿relative_pathä¿¡æ¯æ­£ç¡®
                    original_path = data.get('audio_file', data.get('original_path', ''))
                    relative_path = data.get('relative_path', '')
                    
                    # å¦‚æœæ²¡æœ‰relative_pathï¼Œå°è¯•ä»original_pathæ¨å¯¼
                    if not relative_path and original_path:
                        relative_path = os.path.basename(original_path)
                    
                    audio_info.append({
                        'original_path': original_path,
                        'relative_path': relative_path,
                        'filename': data.get('filename', os.path.basename(original_path)),
                        'duration': data.get('duration', 0.0),
                        'embedding_dim': data.get('embedding_dim', len(embedding))
                    })
                else:
                    failed_count += 1
            except Exception as e:
                print(f"âš ï¸ å¤„ç†embeddingæ•°æ®å¤±è´¥: {e}")
                failed_count += 1
        
        embeddings = np.array(embeddings) if embeddings else np.array([]).reshape(0, -1)
        
        print(f"ğŸ“Š æœ‰æ•ˆembedding: {len(embeddings)}, å¤±è´¥: {failed_count}")
        if len(embeddings) > 0:
            print(f"ğŸ¯ Embeddingç»´åº¦: {embeddings.shape[1]}")
        
        return embeddings, audio_info, []
        
    except Exception as e:
        print(f"âŒ åŠ è½½embeddingæ–‡ä»¶å¤±è´¥: {e}")
        return np.array([]).reshape(0, -1), [], []

def load_embeddings_from_individual_files(embeddings_dir):
    """ä»å•ç‹¬çš„embeddingæ–‡ä»¶ç›®å½•åŠ è½½æ•°æ®"""
    print(f"ğŸ“‚ æ‰«æå•ç‹¬çš„embeddingæ–‡ä»¶: {embeddings_dir}")
    
    embedding_files = []
    
    for root, dirs, files in os.walk(embeddings_dir):
        for file in files:
            if file.endswith('.pkl'):
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, embeddings_dir)
                embedding_files.append({
                    'full_path': full_path,
                    'relative_path': rel_path,
                    'filename': file
                })
    
    # æŒ‰ç›¸å¯¹è·¯å¾„æ’åº
    embedding_files.sort(key=lambda x: x['relative_path'])
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(embedding_files)} ä¸ªembeddingæ–‡ä»¶")
    
    # åŠ è½½æ‰€æœ‰embedding
    print("ğŸ¯ åŠ è½½æ‰€æœ‰embeddingæ–‡ä»¶...")
    
    embeddings = []
    audio_info = []
    failed_files = []
    
    for file_info in tqdm(embedding_files, desc="åŠ è½½embedding"):
        try:
            with open(file_info['full_path'], 'rb') as f:
                data = pickle.load(f)
            
            embedding = data['embedding']
            if embedding is not None and len(embedding) > 0:
                embeddings.append(embedding)
                
                # è·å–éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯
                original_path = data.get('audio_file', data.get('original_path', ''))
                relative_path = data.get('relative_path', '')
                
                # å¦‚æœæ²¡æœ‰relative_pathï¼Œå°è¯•ä»embeddingæ–‡ä»¶è·¯å¾„æ¨å¯¼
                if not relative_path:
                    # ä»embeddingæ–‡ä»¶è·¯å¾„æ¨å¯¼ç›¸å¯¹è·¯å¾„
                    emb_relative_path = file_info['relative_path']
                    # ç§»é™¤.pklæ‰©å±•åï¼Œæ¢å¤éŸ³é¢‘æ–‡ä»¶ç›¸å¯¹è·¯å¾„
                    if emb_relative_path.endswith('.pkl'):
                        # å‡è®¾embeddingæ–‡ä»¶çš„è·¯å¾„ç»“æ„å¯¹åº”éŸ³é¢‘æ–‡ä»¶
                        relative_path = os.path.splitext(emb_relative_path)[0]
                        # å¯èƒ½éœ€è¦æ·»åŠ éŸ³é¢‘æ–‡ä»¶æ‰©å±•åï¼Œä½†è¿™é‡Œå…ˆä¿æŒæ— æ‰©å±•å
                        # åç»­å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                    else:
                        relative_path = emb_relative_path
                
                audio_info.append({
                    'original_path': original_path,
                    'relative_path': relative_path,
                    'filename': data.get('filename', file_info['filename']),
                    'duration': data.get('duration', 0.0),
                    'embedding_file': file_info['full_path']
                })
            else:
                failed_files.append(file_info['full_path'])
                
        except Exception as e:
            print(f"âš ï¸ åŠ è½½embeddingæ–‡ä»¶å¤±è´¥: {file_info['full_path']}, é”™è¯¯: {e}")
            failed_files.append(file_info['full_path'])
    
    embeddings = np.array(embeddings) if embeddings else np.array([]).reshape(0, -1)
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(embeddings)} ä¸ªembeddingï¼Œå¤±è´¥ {len(failed_files)} ä¸ª")
    
    return embeddings, audio_info, failed_files

def calculate_segment_centers(embeddings: np.ndarray, segment_size: int = 1000) -> List[np.ndarray]:
    """è®¡ç®—æ¯ä¸ªæ®µçš„èšç±»ä¸­å¿ƒ"""
    segment_centers = []
    n_segments = (len(embeddings) + segment_size - 1) // segment_size
    
    print(f"ğŸ“Š è®¡ç®— {n_segments} ä¸ªæ®µçš„èšç±»ä¸­å¿ƒ...")
    
    for i in range(n_segments):
        start_idx = i * segment_size
        end_idx = min((i + 1) * segment_size, len(embeddings))
        
        segment_embeddings = embeddings[start_idx:end_idx]
        center = np.mean(segment_embeddings, axis=0)
        segment_centers.append(center)
        
        print(f"  æ®µ {i+1}: [{start_idx}:{end_idx}] -> ä¸­å¿ƒè®¡ç®—å®Œæˆ")
    
    return segment_centers

def train_speaker_gmm(embeddings: np.ndarray, segment_name: str = "", n_components: int = 2, 
                     min_samples: int = 10) -> Optional[GaussianMixture]:
    """ä¸ºè¯´è¯äººæ®µè®­ç»ƒé«˜æ–¯æ··åˆæ¨¡å‹"""
    if len(embeddings) < min_samples:
        print(f"    âš ï¸ {segment_name} æ ·æœ¬æ•°é‡ä¸è¶³({len(embeddings)} < {min_samples})ï¼Œè·³è¿‡GMMè®­ç»ƒ")
        return None
    
    # å¦‚æœæ ·æœ¬æ•°å°‘äºç»„ä»¶æ•°çš„5å€ï¼Œå‡å°‘ç»„ä»¶æ•°
    if len(embeddings) < n_components * 5:
        n_components = max(1, len(embeddings) // 5)
        print(f"    ğŸ“‰ {segment_name} æ ·æœ¬æ•°é‡è¾ƒå°‘ï¼Œè°ƒæ•´GMMç»„ä»¶æ•°ä¸º {n_components}")
    
    try:
        gmm = GaussianMixture(
            n_components=n_components,
            covariance_type='full',
            random_state=42,
            max_iter=100,
            n_init=3
        )
        
        gmm.fit(embeddings)
        
        if not gmm.converged_:
            print(f"    âš ï¸ {segment_name} GMMæœªæ”¶æ•›ï¼Œä½¿ç”¨ç®€å•å‡å€¼ä»£æ›¿")
            return None
            
        bic = gmm.bic(embeddings)
        aic = gmm.aic(embeddings)
        
        print(f"    âœ… {segment_name} GMMè®­ç»ƒæˆåŠŸ: {n_components}ç»„ä»¶, BIC={bic:.2f}, AIC={aic:.2f}")
        
        return gmm
        
    except Exception as e:
        print(f"    âŒ {segment_name} GMMè®­ç»ƒå¤±è´¥: {str(e)}")
        return None

def calculate_gmm_probability(embeddings: np.ndarray, gmm: GaussianMixture) -> float:
    """è®¡ç®—embeddingå‘é‡åœ¨GMMæ¨¡å‹ä¸‹çš„å¯¹æ•°æ¦‚ç‡"""
    if gmm is None or len(embeddings) == 0:
        return -np.inf
    
    try:
        log_probs = gmm.score_samples(embeddings)
        return np.mean(log_probs)
    except Exception as e:
        print(f"    âš ï¸ GMMæ¦‚ç‡è®¡ç®—å¤±è´¥: {str(e)}")
        return -np.inf

def calculate_boundary_gmm_scores(embeddings: np.ndarray, boundary_idx: int, 
                                left_gmm: GaussianMixture, right_gmm: GaussianMixture,
                                window_size: int = 5) -> Tuple[float, Dict]:
    """ä½¿ç”¨GMMæ¨¡å‹è®¡ç®—è¾¹ç•Œç‚¹çš„åˆ†å‰²è´¨é‡"""
    # è·å–è¾¹ç•Œé™„è¿‘çš„embedding
    start_idx = max(0, boundary_idx - window_size)
    end_idx = min(len(embeddings), boundary_idx + window_size)
    
    left_embeddings = embeddings[start_idx:boundary_idx]
    right_embeddings = embeddings[boundary_idx:end_idx]
    
    if len(left_embeddings) == 0 or len(right_embeddings) == 0:
        return -np.inf, {'error': 'Empty segments'}
    
    # è®¡ç®—å·¦æ®µembeddingåœ¨å·¦GMMå’Œå³GMMä¸­çš„æ¦‚ç‡
    left_in_left_prob = calculate_gmm_probability(left_embeddings, left_gmm)
    left_in_right_prob = calculate_gmm_probability(left_embeddings, right_gmm)
    
    # è®¡ç®—å³æ®µembeddingåœ¨å·¦GMMå’Œå³GMMä¸­çš„æ¦‚ç‡
    right_in_left_prob = calculate_gmm_probability(right_embeddings, left_gmm)
    right_in_right_prob = calculate_gmm_probability(right_embeddings, right_gmm)
    
    # è®¡ç®—åˆ†å‰²è´¨é‡ï¼šæ­£ç¡®åˆ†ç±»çš„æ¦‚ç‡ - é”™è¯¯åˆ†ç±»çš„æ¦‚ç‡
    correct_assignment = left_in_left_prob + right_in_right_prob
    wrong_assignment = left_in_right_prob + right_in_left_prob
    
    separation_score = correct_assignment - wrong_assignment
    
    debug_info = {
        'left_in_left_prob': left_in_left_prob,
        'left_in_right_prob': left_in_right_prob,
        'right_in_left_prob': right_in_left_prob,
        'right_in_right_prob': right_in_right_prob,
        'correct_assignment': correct_assignment,
        'wrong_assignment': wrong_assignment,
        'separation_score': separation_score,
        'left_segment_size': len(left_embeddings),
        'right_segment_size': len(right_embeddings)
    }
    
    return separation_score, debug_info

def find_precise_boundary(embeddings: np.ndarray, theoretical_boundary: int, 
                         left_center: np.ndarray, right_center: np.ndarray,
                         boundary_window: int = 10, debug: bool = False) -> Tuple[int, Dict]:
    """åœ¨ç†è®ºåˆ†ç•Œç‚¹é™„è¿‘æ‰¾åˆ°ç²¾ç¡®çš„åˆ†ç•Œç‚¹"""
    start_idx = max(0, theoretical_boundary - boundary_window)
    end_idx = min(len(embeddings), theoretical_boundary + boundary_window + 1)
    
    if start_idx >= end_idx:
        return theoretical_boundary, {'validation': {'overall_accuracy': 0.0}}
    
    best_boundary = theoretical_boundary
    best_score = float('-inf')
    boundary_scores = []
    
    # åœ¨çª—å£å†…æœç´¢æœ€ä½³è¾¹ç•Œ
    for candidate_boundary in range(start_idx, end_idx):
        if candidate_boundary == 0 or candidate_boundary >= len(embeddings):
            continue
        
        # è®¡ç®—å·¦å³ä¸¤ä¾§ä¸å„è‡ªä¸­å¿ƒçš„ç›¸ä¼¼åº¦
        left_embeddings = embeddings[:candidate_boundary]
        right_embeddings = embeddings[candidate_boundary:]
        
        if len(left_embeddings) == 0 or len(right_embeddings) == 0:
            continue
        
        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        left_similarities = cosine_similarity(left_embeddings, [left_center]).flatten()
        right_similarities = cosine_similarity(right_embeddings, [right_center]).flatten()
        
        # æ€»åˆ†æ•° = å·¦ä¾§ç›¸ä¼¼åº¦å‡å€¼ + å³ä¾§ç›¸ä¼¼åº¦å‡å€¼
        score = np.mean(left_similarities) + np.mean(right_similarities)
        boundary_scores.append((candidate_boundary, score))
        
        if score > best_score:
            best_score = score
            best_boundary = candidate_boundary
    
    # è¾¹ç•ŒéªŒè¯
    validation_info = {}
    if best_boundary > 0 and best_boundary < len(embeddings):
        left_embeddings = embeddings[:best_boundary]
        right_embeddings = embeddings[best_boundary:]
        
        if len(left_embeddings) > 0 and len(right_embeddings) > 0:
            left_sims = cosine_similarity(left_embeddings, [left_center]).flatten()
            right_sims = cosine_similarity(right_embeddings, [right_center]).flatten()
            
            # è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡
            left_correct = np.sum(left_sims > 0.5)
            right_correct = np.sum(right_sims > 0.5)
            total_correct = left_correct + right_correct
            total_samples = len(left_embeddings) + len(right_embeddings)
            
            validation_info = {
                'overall_accuracy': total_correct / total_samples if total_samples > 0 else 0,
                'left_accuracy': left_correct / len(left_embeddings),
                'right_accuracy': right_correct / len(right_embeddings),
                'left_avg_similarity': float(np.mean(left_sims)),
                'right_avg_similarity': float(np.mean(right_sims)),
                'boundary_score': float(best_score)
            }
    
    debug_info = {
        'theoretical_boundary': theoretical_boundary,
        'search_window': [start_idx, end_idx],
        'boundary_scores': boundary_scores if debug else [],
        'validation': validation_info
    }
    
    return best_boundary, debug_info

def find_precise_boundary_gmm(embeddings: np.ndarray, theoretical_boundary: int, 
                             left_gmm: GaussianMixture, right_gmm: GaussianMixture,
                             boundary_window: int = 10, debug: bool = False) -> Tuple[int, Dict]:
    """ä½¿ç”¨GMMæ¨¡å‹åœ¨ç†è®ºåˆ†ç•Œç‚¹é™„è¿‘æ‰¾åˆ°ç²¾ç¡®çš„åˆ†ç•Œç‚¹"""
    start_idx = max(0, theoretical_boundary - boundary_window)
    end_idx = min(len(embeddings), theoretical_boundary + boundary_window + 1)
    
    if start_idx >= end_idx:
        return theoretical_boundary, {'validation': {'overall_accuracy': 0.0}}
    
    best_boundary = theoretical_boundary
    best_score = float('-inf')
    best_debug_info = {}
    
    print(f"      ğŸ” GMMè¾¹ç•Œæœç´¢èŒƒå›´: [{start_idx}:{end_idx}]")
    
    scores = []
    for boundary_idx in range(start_idx, end_idx):
        score, debug_info = calculate_boundary_gmm_scores(
            embeddings, boundary_idx, left_gmm, right_gmm, window_size=5
        )
        
        scores.append(score)
        
        if debug:
            print(f"        ä½ç½® {boundary_idx}: GMMåˆ†ç¦»åº¦={score:.4f}")
        
        if score > best_score:
            best_score = score
            best_boundary = boundary_idx
            best_debug_info = debug_info
    
    # è®¡ç®—éªŒè¯ä¿¡æ¯
    validation_info = {
        'overall_accuracy': min(1.0, max(0.0, (best_score + 10) / 20)),  # å½’ä¸€åŒ–åˆ°0-1
        'separation_score': best_score,
        'search_range': [start_idx, end_idx],
        'scores': scores
    }
    
    best_debug_info.update({
        'theoretical_boundary': theoretical_boundary,
        'best_boundary': best_boundary,
        'best_score': best_score,
        'search_window': boundary_window,
        'method': 'GMM',
        'validation': validation_info
    })
    
    print(f"      âœ… GMMæœ€ä½³è¾¹ç•Œ: {best_boundary} (åˆ†ç¦»åº¦: {best_score:.4f})")
    
    return best_boundary, best_debug_info

def detect_speaker_boundaries_gmm(embeddings: np.ndarray, audio_info: List[Dict], 
                                segment_size: int = 1000, boundary_window: int = 10, 
                                n_components: int = 2, debug: bool = False) -> Tuple[List[int], Dict]:
    """åŸºäºæ··åˆé«˜æ–¯æ¨¡å‹(GMM)çš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹"""
    
    if len(embeddings) <= segment_size:
        print("âš ï¸ éŸ³é¢‘æ–‡ä»¶æ•°é‡å°‘äºsegment_sizeï¼Œä¸è¿›è¡Œè¾¹ç•Œæ£€æµ‹")
        boundaries = [0, len(embeddings)]
        debug_info = {
            'total_segments': 1,
            'theoretical_boundaries': [],
            'boundary_debug_info': [],
            'gmm_algorithm': True
        }
        return boundaries, debug_info
    
    print(f"ğŸ­ å¼€å§‹åŸºäºGMMçš„è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼Œé¢„è®¡æ®µæ•°åŸºäº segment_size={segment_size}...")
    print(f"ğŸ§  æ¯ä¸ªè¯´è¯äººå°†è®­ç»ƒ {n_components} ä¸ªèšç±»ä¸­å¿ƒçš„GMMæ¨¡å‹")
    print(f"ğŸ“ ä½¿ç”¨è‡ªé€‚åº”ç®—æ³•ï¼šæ ¹æ®å®é™…è¾¹ç•Œé‡æ–°è®¡ç®—åç»­èµ·ç‚¹")
    
    boundaries = [0]  # èµ·å§‹è¾¹ç•Œ
    boundary_debug_info = []
    theoretical_boundaries = []
    gmm_models = []  # å­˜å‚¨æ¯ä¸ªæ®µçš„GMMæ¨¡å‹
    
    # è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼šæ¯æ¬¡åŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œè®¡ç®—ä¸‹ä¸€ä¸ªç†è®ºè¾¹ç•Œ
    current_start = 0
    segment_index = 0
    
    while current_start + segment_size < len(embeddings):
        # è®¡ç®—å½“å‰ç†è®ºè¾¹ç•Œä½ç½®ï¼ˆåŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œï¼‰
        theoretical_boundary = current_start + segment_size
        theoretical_boundaries.append(theoretical_boundary)
        
        # ç¡®ä¿ä¸è¶…å‡ºæ•°ç»„èŒƒå›´
        if theoretical_boundary >= len(embeddings):
            break
        
        print(f"  ğŸ¯ æ£€æµ‹è¾¹ç•Œ {segment_index+1} (ç†è®ºä½ç½®: {theoretical_boundary})")
        
        # è®­ç»ƒå½“å‰æ®µçš„GMMæ¨¡å‹ï¼ˆæ’é™¤è¾¹ç•Œé™„è¿‘çš„éŸ³é¢‘ï¼‰
        current_segment_end = min(theoretical_boundary, len(embeddings))
        # å·¦æ®µæ’é™¤æ¥è¿‘è¾¹ç•Œçš„åé¢éƒ¨åˆ†ï¼Œä½†ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®
        left_train_end = max(current_start + boundary_window, current_segment_end - boundary_window)
        if left_train_end <= current_start:
            left_train_end = current_segment_end  # å¦‚æœç¼“å†²åŒºå¤ªå¤§ï¼Œä½¿ç”¨å®Œæ•´æ®µ
        left_embeddings = embeddings[current_start:left_train_end]
        
        print(f"    ğŸ—ï¸ è®­ç»ƒå·¦æ®µGMMæ¨¡å‹ (èŒƒå›´: [{current_start}:{left_train_end}], {len(left_embeddings)} ä¸ªæ ·æœ¬, æ’é™¤è¾¹ç•Œç¼“å†²åŒº)")
        left_gmm = train_speaker_gmm(
            left_embeddings, 
            segment_name=f"å·¦æ®µ{segment_index+1}", 
            n_components=n_components
        )
        
        # è®­ç»ƒä¸‹ä¸€æ®µçš„GMMæ¨¡å‹ï¼ˆæ’é™¤è¾¹ç•Œé™„è¿‘çš„éŸ³é¢‘ï¼‰
        next_segment_start = theoretical_boundary
        next_segment_end = min(next_segment_start + segment_size, len(embeddings))
        # å³æ®µæ’é™¤æ¥è¿‘è¾¹ç•Œçš„å‰é¢éƒ¨åˆ†ï¼Œä½†ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®
        right_train_start = min(next_segment_start + boundary_window, next_segment_end - boundary_window)
        if right_train_start >= next_segment_end:
            right_train_start = next_segment_start  # å¦‚æœç¼“å†²åŒºå¤ªå¤§ï¼Œä½¿ç”¨å®Œæ•´æ®µ
        right_embeddings = embeddings[right_train_start:next_segment_end]
        
        print(f"    ğŸ—ï¸ è®­ç»ƒå³æ®µGMMæ¨¡å‹ (èŒƒå›´: [{right_train_start}:{next_segment_end}], {len(right_embeddings)} ä¸ªæ ·æœ¬, æ’é™¤è¾¹ç•Œç¼“å†²åŒº)")
        right_gmm = train_speaker_gmm(
            right_embeddings, 
            segment_name=f"å³æ®µ{segment_index+2}", 
            n_components=n_components
        )
        
        # å¦‚æœGMMè®­ç»ƒå¤±è´¥ï¼Œå›é€€åˆ°ä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•
        if left_gmm is None or right_gmm is None:
            print(f"    âš ï¸ GMMè®­ç»ƒå¤±è´¥ï¼Œå›é€€åˆ°ä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•")
            left_center = np.mean(left_embeddings, axis=0)
            right_center = np.mean(right_embeddings, axis=0)
            
            precise_boundary, debug_info = find_precise_boundary(
                embeddings, theoretical_boundary, left_center, right_center, 
                boundary_window, debug
            )
            debug_info['fallback_to_cosine'] = True
        else:
            # ä½¿ç”¨GMMæ¨¡å‹è¿›è¡Œç²¾ç¡®è¾¹ç•Œæ£€æµ‹
            print(f"    ğŸ” ä½¿ç”¨GMMæ¨¡å‹æœç´¢ç²¾ç¡®è¾¹ç•Œ (çª—å£: Â±{boundary_window})")
            precise_boundary, debug_info = find_precise_boundary_gmm(
                embeddings, theoretical_boundary, left_gmm, right_gmm, 
                boundary_window, debug
            )
            debug_info['fallback_to_cosine'] = False
        
        boundaries.append(precise_boundary)
        debug_info['segment_index'] = segment_index + 1
        debug_info['current_start'] = current_start
        debug_info['theoretical_boundary'] = theoretical_boundary
        debug_info['actual_segment_size'] = precise_boundary - current_start
        boundary_debug_info.append(debug_info)
        
        # å­˜å‚¨GMMæ¨¡å‹
        gmm_models.append({
            'segment_index': segment_index + 1,
            'left_gmm': left_gmm,
            'right_gmm': right_gmm,
            'boundaries': [current_start, precise_boundary]
        })
        
        # è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        actual_segment_size = precise_boundary - current_start
        offset = precise_boundary - theoretical_boundary
        
        if 'validation' in debug_info and 'overall_accuracy' in debug_info['validation']:
            accuracy = debug_info['validation']['overall_accuracy']
            print(f"    âœ… ç²¾ç¡®è¾¹ç•Œ: {precise_boundary}")
            print(f"    ğŸ“Š å®é™…æ®µå¤§å°: {actual_segment_size} (ç›®æ ‡: {segment_size}, åå·®: {actual_segment_size - segment_size})")
            print(f"    ğŸ“ è¾¹ç•Œåç§»: {offset}, å‡†ç¡®ç‡: {accuracy:.2%}")
        else:
            print(f"    âœ… ç²¾ç¡®è¾¹ç•Œ: {precise_boundary} (åç§»: {offset})")
            print(f"    ğŸ“Š å®é™…æ®µå¤§å°: {actual_segment_size} (ç›®æ ‡: {segment_size}, åå·®: {actual_segment_size - segment_size})")
        
        # æ›´æ–°ä¸‹ä¸€è½®çš„èµ·ç‚¹ä¸ºå½“å‰æ£€æµ‹åˆ°çš„å®é™…è¾¹ç•Œ
        current_start = precise_boundary
        segment_index += 1
        
        # å·²ç§»é™¤æ®µæ•°é™åˆ¶ï¼Œç»§ç»­å¤„ç†æ‰€æœ‰æ•°æ®
    
    boundaries.append(len(embeddings))  # ç»“æŸè¾¹ç•Œ
    
    # ç»Ÿè®¡ä¿¡æ¯
    actual_segments = len(boundaries) - 1
    print(f"\nğŸ“Š GMMè¾¹ç•Œæ£€æµ‹ç»Ÿè®¡ï¼š")
    print(f"   å®é™…æ®µæ•°: {actual_segments}")
    print(f"   GMMç»„ä»¶æ•°: {n_components}")
    print(f"   æ®µå¤§å°ç»Ÿè®¡:")
    
    for i in range(len(boundaries) - 1):
        start_idx = boundaries[i]
        end_idx = boundaries[i + 1]
        segment_size_actual = end_idx - start_idx
        print(f"     æ®µ {i+1}: {segment_size_actual} ä¸ªæ–‡ä»¶ (èŒƒå›´: [{start_idx}:{end_idx}])")
    
    # ä¸ºJSONåºåˆ—åŒ–å‡†å¤‡GMMæ¨¡å‹æ‘˜è¦ä¿¡æ¯ï¼ˆç§»é™¤ä¸å¯åºåˆ—åŒ–çš„GMMå¯¹è±¡ï¼‰
    gmm_models_summary = []
    for gmm_info in gmm_models:
        summary = {
            'segment_index': gmm_info['segment_index'],
            'boundaries': gmm_info['boundaries'],
            'left_gmm_trained': gmm_info['left_gmm'] is not None,
            'right_gmm_trained': gmm_info['right_gmm'] is not None
        }
        gmm_models_summary.append(summary)
    
    combined_debug = {
        'total_segments': actual_segments,
        'theoretical_boundaries': theoretical_boundaries,
        'boundary_debug_info': boundary_debug_info,
        'gmm_algorithm': True,
        'gmm_components': n_components,
        'gmm_models_summary': gmm_models_summary,  # ä½¿ç”¨æ‘˜è¦è€Œä¸æ˜¯å®Œæ•´å¯¹è±¡
        'target_segment_size': segment_size,
        'actual_segment_sizes': [boundaries[i+1] - boundaries[i] for i in range(len(boundaries)-1)]
    }
    
    return boundaries, combined_debug

def detect_speaker_boundaries(embeddings: np.ndarray, audio_info: List[Dict], 
                            segment_size: int = 1000, boundary_window: int = 10, 
                            debug: bool = False) -> Tuple[List[int], Dict]:
    """æ£€æµ‹è¯´è¯äººè¾¹ç•Œï¼ˆåŸºäºç´¯ç§¯å®é™…è¾¹ç•Œçš„è‡ªé€‚åº”ç®—æ³•ï¼‰"""
    
    if len(embeddings) <= segment_size:
        print("âš ï¸ éŸ³é¢‘æ–‡ä»¶æ•°é‡å°‘äºsegment_sizeï¼Œä¸è¿›è¡Œè¾¹ç•Œæ£€æµ‹")
        boundaries = [0, len(embeddings)]
        debug_info = {
            'total_segments': 1,
            'theoretical_boundaries': [],
            'boundary_debug_info': []
        }
        return boundaries, debug_info
    
    # è®¡ç®—æ®µä¸­å¿ƒï¼ˆç”¨äºåˆå§‹å‚è€ƒï¼‰
    segment_centers = calculate_segment_centers(embeddings, segment_size)
    n_segments = len(segment_centers)
    
    print(f"ğŸ” å¼€å§‹è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼Œé¢„è®¡ {n_segments} ä¸ªæ®µ...")
    print(f"ğŸ“ ä½¿ç”¨è‡ªé€‚åº”ç®—æ³•ï¼šæ ¹æ®å®é™…è¾¹ç•Œé‡æ–°è®¡ç®—åç»­èµ·ç‚¹")
    
    boundaries = [0]  # èµ·å§‹è¾¹ç•Œ
    boundary_debug_info = []
    theoretical_boundaries = []
    
    # è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼šæ¯æ¬¡åŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œè®¡ç®—ä¸‹ä¸€ä¸ªç†è®ºè¾¹ç•Œ
    current_start = 0
    segment_index = 0
    
    while current_start + segment_size < len(embeddings):
        # è®¡ç®—å½“å‰ç†è®ºè¾¹ç•Œä½ç½®ï¼ˆåŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œï¼‰
        theoretical_boundary = current_start + segment_size
        theoretical_boundaries.append(theoretical_boundary)
        
        # ç¡®ä¿ä¸è¶…å‡ºæ•°ç»„èŒƒå›´
        if theoretical_boundary >= len(embeddings):
            break
        
        # é‡æ–°è®¡ç®—å½“å‰æ®µå’Œä¸‹ä¸€æ®µçš„ä¸­å¿ƒï¼ˆæ’é™¤è¾¹ç•Œé™„è¿‘çš„éŸ³é¢‘ï¼‰
        # å½“å‰æ®µï¼šä»ä¸Šä¸€ä¸ªå®é™…è¾¹ç•Œåˆ°ç†è®ºè¾¹ç•Œï¼Œæ’é™¤æ¥è¿‘è¾¹ç•Œçš„åé¢éƒ¨åˆ†
        current_segment_end = min(theoretical_boundary, len(embeddings))
        left_train_end = max(current_start + boundary_window, current_segment_end - boundary_window)
        if left_train_end <= current_start:
            left_train_end = current_segment_end  # å¦‚æœç¼“å†²åŒºå¤ªå¤§ï¼Œä½¿ç”¨å®Œæ•´æ®µ
        left_embeddings = embeddings[current_start:left_train_end]
        left_center = np.mean(left_embeddings, axis=0)
        
        # ä¸‹ä¸€æ®µï¼šä»ç†è®ºè¾¹ç•Œåˆ°ç†è®ºè¾¹ç•Œ+segment_sizeï¼Œæ’é™¤æ¥è¿‘è¾¹ç•Œçš„å‰é¢éƒ¨åˆ†
        next_segment_start = theoretical_boundary
        next_segment_end = min(next_segment_start + segment_size, len(embeddings))
        right_train_start = min(next_segment_start + boundary_window, next_segment_end - boundary_window)
        if right_train_start >= next_segment_end:
            right_train_start = next_segment_start  # å¦‚æœç¼“å†²åŒºå¤ªå¤§ï¼Œä½¿ç”¨å®Œæ•´æ®µ
        right_embeddings = embeddings[right_train_start:next_segment_end]
        right_center = np.mean(right_embeddings, axis=0)
        
        print(f"  ğŸ¯ æ£€æµ‹è¾¹ç•Œ {segment_index+1} (ç†è®ºä½ç½®: {theoretical_boundary})")
        print(f"    å·¦æ®µè®­ç»ƒèŒƒå›´: [{current_start}:{left_train_end}] ({len(left_embeddings)} ä¸ªæ–‡ä»¶, æ’é™¤è¾¹ç•Œç¼“å†²åŒº)")
        print(f"    å³æ®µè®­ç»ƒèŒƒå›´: [{right_train_start}:{next_segment_end}] ({len(right_embeddings)} ä¸ªæ–‡ä»¶, æ’é™¤è¾¹ç•Œç¼“å†²åŒº)")
        
        # åœ¨ç†è®ºè¾¹ç•Œé™„è¿‘æœç´¢ç²¾ç¡®è¾¹ç•Œ
        precise_boundary, debug_info = find_precise_boundary(
            embeddings, theoretical_boundary, left_center, right_center, 
            boundary_window, debug
        )
        
        boundaries.append(precise_boundary)
        debug_info['segment_index'] = segment_index + 1
        debug_info['current_start'] = current_start
        debug_info['theoretical_boundary'] = theoretical_boundary
        debug_info['actual_segment_size'] = precise_boundary - current_start
        boundary_debug_info.append(debug_info)
        
        accuracy = debug_info['validation']['overall_accuracy']
        actual_segment_size = precise_boundary - current_start
        offset = precise_boundary - theoretical_boundary
        
        print(f"    âœ… ç²¾ç¡®è¾¹ç•Œ: {precise_boundary}")
        print(f"    ğŸ“Š å®é™…æ®µå¤§å°: {actual_segment_size} (ç›®æ ‡: {segment_size}, åå·®: {actual_segment_size - segment_size})")
        print(f"    ğŸ“ è¾¹ç•Œåç§»: {offset}, å‡†ç¡®ç‡: {accuracy:.2%}")
        
        # æ›´æ–°ä¸‹ä¸€è½®çš„èµ·ç‚¹ä¸ºå½“å‰æ£€æµ‹åˆ°çš„å®é™…è¾¹ç•Œ
        current_start = precise_boundary
        segment_index += 1
        
        # å·²ç§»é™¤æ®µæ•°é™åˆ¶ï¼Œç»§ç»­å¤„ç†æ‰€æœ‰æ•°æ®
    
    boundaries.append(len(embeddings))  # ç»“æŸè¾¹ç•Œ
    
    # ç»Ÿè®¡ä¿¡æ¯
    actual_segments = len(boundaries) - 1
    print(f"\nğŸ“Š è¾¹ç•Œæ£€æµ‹ç»Ÿè®¡ï¼š")
    print(f"   é¢„è®¡æ®µæ•°: {n_segments}")
    print(f"   å®é™…æ®µæ•°: {actual_segments}")
    print(f"   æ®µå¤§å°ç»Ÿè®¡:")
    
    for i in range(len(boundaries) - 1):
        start_idx = boundaries[i]
        end_idx = boundaries[i + 1]
        segment_size_actual = end_idx - start_idx
        print(f"     æ®µ {i+1}: {segment_size_actual} ä¸ªæ–‡ä»¶ (èŒƒå›´: [{start_idx}:{end_idx}])")
    
    combined_debug = {
        'total_segments': actual_segments,
        'theoretical_boundaries': theoretical_boundaries,
        'boundary_debug_info': boundary_debug_info,
        'adaptive_algorithm': True,
        'target_segment_size': segment_size,
        'actual_segment_sizes': [boundaries[i+1] - boundaries[i] for i in range(len(boundaries)-1)]
    }
    
    return boundaries, combined_debug

def convert_to_json_serializable(obj):
    """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼"""
    try:
        # é¦–å…ˆæ£€æŸ¥åŸºæœ¬çš„JSONå¯åºåˆ—åŒ–ç±»å‹
        json.dumps(obj)
        return obj
    except (TypeError, ValueError):
        # å¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif hasattr(obj, '__class__') and 'sklearn' in str(obj.__class__):
            # å¤„ç†sklearnå¯¹è±¡ï¼ˆå¦‚GaussianMixtureï¼‰ï¼Œè¿”å›æè¿°ä¿¡æ¯
            return f"<sklearn.{obj.__class__.__name__} object>"
        elif isinstance(obj, dict):
            return {k: convert_to_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [convert_to_json_serializable(item) for item in obj]
        else:
            # å¯¹äºå…¶ä»–ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œè¿”å›å­—ç¬¦ä¸²æè¿°
            return f"<{obj.__class__.__name__} object>"

def save_results(boundaries: List[int], debug_info: Dict, audio_info: List[Dict], output_dir: str) -> Dict:
    """ä¿å­˜æ£€æµ‹ç»“æœå¹¶åˆ†å‰²éŸ³é¢‘æ–‡ä»¶"""
    print("ğŸ’¾ ä¿å­˜ç»“æœå¹¶åˆ†å‰²éŸ³é¢‘æ–‡ä»¶...")
    
    speakers = []
    
    for i in range(len(boundaries) - 1):
        start_idx = boundaries[i]
        end_idx = boundaries[i + 1]
        file_count = end_idx - start_idx
        
        speaker_info = {
            'speaker_id': f'speaker_{i+1:03d}',
            'start_index': start_idx,
            'end_index': end_idx,
            'file_count': file_count,
            'audio_files': []
        }
        
        # åˆ›å»ºè¯´è¯äººç›®å½•
        speaker_dir = os.path.join(output_dir, speaker_info['speaker_id'])
        os.makedirs(speaker_dir, exist_ok=True)
        
        # å¤åˆ¶æˆ–é“¾æ¥éŸ³é¢‘æ–‡ä»¶ï¼Œä¿æŒåŸå§‹ç›®å½•ç»“æ„
        for j in range(start_idx, min(end_idx, len(audio_info))):
            audio_data = audio_info[j]
            original_path = audio_data['original_path']
            relative_path = audio_data.get('relative_path', '')
            filename = audio_data.get('filename', '')
            
            if original_path and os.path.exists(original_path):
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä¿æŒç›®å½•ç»“æ„ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ–‡ä»¶å
                if relative_path:
                    # ä¿æŒå®Œæ•´çš„ç›¸å¯¹è·¯å¾„ç»“æ„
                    dst_file = os.path.join(speaker_dir, relative_path)
                    stored_path = relative_path
                else:
                    # å¦‚æœæ²¡æœ‰ç›¸å¯¹è·¯å¾„ï¼Œåªä½¿ç”¨æ–‡ä»¶å
                    original_filename = os.path.basename(original_path)
                    dst_file = os.path.join(speaker_dir, original_filename)
                    stored_path = original_filename
                
                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                dst_dir = os.path.dirname(dst_file)
                if dst_dir and dst_dir != speaker_dir:
                    os.makedirs(dst_dir, exist_ok=True)
                
                try:
                    # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
                    shutil.copy2(original_path, dst_file)
                    speaker_info['audio_files'].append(stored_path)
                except Exception as e:
                    print(f"âš ï¸ å¤åˆ¶æ–‡ä»¶å¤±è´¥: {original_path} -> {dst_file}, é”™è¯¯: {e}")
            else:
                print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©º: {original_path}")
        
        speakers.append(speaker_info)
    
    result = {
        'boundaries': boundaries,
        'speakers': speakers,
        'debug_info': debug_info,
        'total_audio_files': len(audio_info),
        'detected_speakers': len(speakers)
    }
    
    # ä¿å­˜JSONç»“æœï¼ˆè½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼ï¼‰
    result_file = os.path.join(output_dir, 'speaker_boundary_detection_result.json')
    json_serializable_result = convert_to_json_serializable(result)
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(json_serializable_result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜: {result_file}")
    print(f"   æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº")
    print(f"   è¾¹ç•Œä½ç½®: {boundaries}")
    
    # æ˜¾ç¤ºæ¯ä¸ªè¯´è¯äººçš„æ–‡ä»¶æ•°é‡
    for speaker in speakers:
        print(f"   {speaker['speaker_id']}: {speaker['file_count']} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    
    return result

def plot_boundary_visualization(embeddings: np.ndarray, boundaries: List[int], 
                               debug_info: Dict, output_file: str):
    """ç”Ÿæˆè¾¹ç•Œæ£€æµ‹å¯è§†åŒ–å›¾"""
    try:
        if len(embeddings) == 0:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„embeddingæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        plt.figure(figsize=(15, 10))
        
        # è®¡ç®—PCAé™ç»´ç”¨äºå¯è§†åŒ–
        if embeddings.shape[1] > 2:
            from sklearn.decomposition import PCA
            pca = PCA(n_components=2)
            embeddings_2d = pca.fit_transform(embeddings)
        else:
            embeddings_2d = embeddings
        
        # ç»˜åˆ¶embeddingsæ•£ç‚¹å›¾
        plt.subplot(2, 1, 1)
        scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], 
                            c=range(len(embeddings_2d)), cmap='tab10', alpha=0.6, s=10)
        plt.colorbar(scatter, label='File Index')
        plt.title('Speaker Embeddings Visualization (PCA)')
        plt.xlabel('PCA Component 1')
        plt.ylabel('PCA Component 2')
        
        # ç»˜åˆ¶è¾¹ç•Œçº¿
        for i, boundary in enumerate(boundaries[1:-1], 1):
            if boundary < len(embeddings):
                point = embeddings_2d[boundary]
                plt.axvline(x=point[0], color='red', linestyle='--', alpha=0.7, 
                          label=f'Boundary {i}' if i == 1 else "")
        
        if len(boundaries) > 2:
            plt.legend()
        
        # ç»˜åˆ¶ç›¸ä¼¼åº¦æ›²çº¿
        plt.subplot(2, 1, 2)
        if len(embeddings) > 1:
            similarities = []
            for i in range(len(embeddings) - 1):
                sim = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]
                similarities.append(sim)
            
            plt.plot(similarities, alpha=0.7, linewidth=1)
            plt.title('Adjacent File Similarity')
            plt.xlabel('File Index')
            plt.ylabel('Cosine Similarity')
            
            # æ ‡è®°è¾¹ç•Œä½ç½®
            for boundary in boundaries[1:-1]:
                if boundary < len(similarities):
                    plt.axvline(x=boundary, color='red', linestyle='--', alpha=0.7)
                    plt.text(boundary, max(similarities) * 0.9, f'B{boundary}', 
                           rotation=90, ha='right', va='top')
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š å¯è§†åŒ–å›¾å·²ä¿å­˜: {output_file}")
        
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å›¾å¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description="åŸºäºembeddingçš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹")
    parser.add_argument('--embeddings_path', type=str, default="/root/group-shared/voiceprint/data/speech/speech_enhancement/child-2.07M/wav_embeddings_eres2netv2w24s4ep4",
                       help='embeddingæ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯åˆå¹¶çš„pklæ–‡ä»¶æˆ–ç›®å½•ï¼‰')
    parser.add_argument('--output_dir', type=str, default="/root/group-shared/voiceprint/data/speech/speech_enhancement/child-2.07M/wav_embeddings_eres2netv2w24s4ep4_boundaries",
                       help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--segment_size', type=int, default=1000,
                       help='æ¯æ®µçš„é¢„æœŸå¤§å°ï¼ˆé»˜è®¤1000ï¼‰')
    parser.add_argument('--boundary_window', type=int, default=20,
                       help='è¾¹ç•Œæœç´¢çª—å£å¤§å°ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--debug', action='store_true',
                       help='å¼€å¯è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--use_gmm', action='store_true', default=True,
                       help='ä½¿ç”¨æ··åˆé«˜æ–¯æ¨¡å‹(GMM)è¿›è¡Œè¾¹ç•Œæ£€æµ‹')
    parser.add_argument('--gmm_components', type=int, default=1,
                       help='GMMæ¨¡å‹çš„ç»„ä»¶æ•°é‡ï¼ˆé»˜è®¤1ä¸ªèšç±»ä¸­å¿ƒï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„
    if not os.path.exists(args.embeddings_path):
        print(f"âŒ embeddingè·¯å¾„ä¸å­˜åœ¨: {args.embeddings_path}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print(f"ğŸ¯ å¼€å§‹åŸºäºembeddingçš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹")
    print(f"ğŸ“ Embeddingè·¯å¾„: {args.embeddings_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“ æ®µå¤§å°: {args.segment_size}")
    print(f"ğŸ”§ è¾¹ç•Œçª—å£: Â±{args.boundary_window}")
    print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {args.debug}")
    if args.use_gmm:
        print(f"ğŸ­ æ£€æµ‹ç®—æ³•: æ··åˆé«˜æ–¯æ¨¡å‹ (GMM)")
        print(f"ğŸ§  GMMç»„ä»¶æ•°: {args.gmm_components}")
    else:
        print(f"ğŸ¯ æ£€æµ‹ç®—æ³•: ä½™å¼¦ç›¸ä¼¼åº¦")
    print("")
    
    start_time = time.time()
    
    # åŠ è½½embeddings
    if os.path.isfile(args.embeddings_path):
        # å•ä¸ªåˆå¹¶æ–‡ä»¶
        embeddings, audio_info, failed_files = load_embeddings_from_merged_file(args.embeddings_path)
    else:
        # ç›®å½•ä¸­çš„å•ç‹¬æ–‡ä»¶
        embeddings, audio_info, failed_files = load_embeddings_from_individual_files(args.embeddings_path)
    
    if len(embeddings) == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„embeddingæ•°æ®")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(embeddings)} ä¸ªembedding")
    print(f"   ç¬¬ä¸€ä¸ªæ–‡ä»¶: {audio_info[0]['filename'] if audio_info else 'N/A'}")
    print(f"   æœ€åä¸€ä¸ªæ–‡ä»¶: {audio_info[-1]['filename'] if audio_info else 'N/A'}")
    print(f"   Embeddingç»´åº¦: {embeddings.shape[1]}")
    
    # æ£€æµ‹è¯´è¯äººè¾¹ç•Œ
    print("\nğŸ” å¼€å§‹è¯´è¯äººè¾¹ç•Œæ£€æµ‹...")
    if args.use_gmm:
        boundaries, detection_debug = detect_speaker_boundaries_gmm(
            embeddings, audio_info, args.segment_size, args.boundary_window, 
            args.gmm_components, args.debug
        )
    else:
        boundaries, detection_debug = detect_speaker_boundaries(
            embeddings, audio_info, args.segment_size, args.boundary_window, args.debug
        )
    
    # åˆå¹¶è°ƒè¯•ä¿¡æ¯
    combined_debug = {
        'detection': detection_debug,
        'processing_time': time.time() - start_time,
        'failed_files': failed_files,
        'total_embeddings': len(embeddings)
    }
    
    # ä¿å­˜ç»“æœ
    result = save_results(boundaries, combined_debug, audio_info, args.output_dir)
    
    # ç”Ÿæˆå¯è§†åŒ–
    visualization_file = os.path.join(args.output_dir, 'boundary_detection_visualization.png')
    plot_boundary_visualization(embeddings, boundaries, combined_debug, visualization_file)
    
    total_time = time.time() - start_time
    print(f"\nğŸ‰ è¾¹ç•Œæ£€æµ‹å®Œæˆï¼")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"ğŸ¯ æ£€æµ‹åˆ° {len(boundaries) - 1} ä¸ªè¯´è¯äºº")
    print(f"ğŸ“Š å¤„ç†æ•ˆç‡: {len(embeddings)/total_time:.1f} ä¸ªæ–‡ä»¶/ç§’")
    print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {args.output_dir}")

if __name__ == "__main__":
    main()